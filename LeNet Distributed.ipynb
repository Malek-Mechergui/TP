{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (0.15.1)\n",
      "Requirement already satisfied: pyspark in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (3.4.0)\n",
      "Collecting sparktorch\n",
      "  Downloading sparktorch-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: typing-extensions in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: filelock in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: networkx in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: requests in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: numpy in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\n",
      "Collecting flask\n",
      "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 3.2 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: dill in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from sparktorch) (0.3.6)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (50.3.2)\n",
      "Requirement already satisfied: wheel in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (0.40.0)\n",
      "Requirement already satisfied: cmake in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (16.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0; python_version < \"3.10\" in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from flask->sparktorch) (5.0.0)\n",
      "Collecting Werkzeug>=2.2.2\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 161.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click>=8.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 2.0 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /s/chopin/b/grad/bdvision/.local/lib/python3.9/site-packages (from importlib-metadata>=3.6.0; python_version < \"3.10\"->flask->sparktorch) (3.10.0)\n",
      "Installing collected packages: Werkzeug, click, itsdangerous, flask, sparktorch\n",
      "Successfully installed Werkzeug-2.2.3 click-8.1.3 flask-2.2.3 itsdangerous-2.1.2 sparktorch-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sparktorch import serialize_torch_obj, SparkTorch\n",
    "from pyspark.sql import SparkSession\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR'] = 'hartford.cs.colostate.edu'\n",
    "os.environ['MASTER_PORT'] = '31220' # This is for DDP, not Spark's master port\n",
    "os.environ['RANK'] = '0'\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"PyTorch Distributed Training\").getOrCreate()\n",
    "\n",
    "# Initialize the default process group\n",
    "dist.init_process_group(backend=\"gloo\", world_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                 transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "train_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "val_data = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create RDDs from the datasets\n",
    "train_rdd = spark.sparkContext.parallelize([(x.unsqueeze(0), y) for x, y in train_data])\n",
    "val_rdd = spark.sparkContext.parallelize([(x.unsqueeze(0), y) for x, y in val_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "lr=0.001\n",
    "N_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader from the RDD\n",
    "train_loader = DataLoader(train_rdd, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_rdd, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = LeNet5(N_CLASSES)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "# Wrap the model with DistributedDataParallel\n",
    "model = nn.parallel.DistributedDataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.squeeze().to(torch.float32))\n",
    "        loss = nn.functional.nll_loss(output, target.to(torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data.squeeze().to(torch.float32))\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target.to(torch.long)).sum().item()\n",
    "\n",
    "    print(\"Epoch {} Accuracy: {}\".format(epoch+1, correct/total))\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
